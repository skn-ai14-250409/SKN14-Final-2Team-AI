# --- stdlib ---
import json
import re

# --- third-party ---
import requests
import joblib
import numpy as np
import torch
from transformers import AutoTokenizer, AutoModel
from rank_bm25 import BM25Okapi

# --- langchain ---
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.tools import tool
# from config import llm, index, naver_client_id, naver_client_secret
from .config import llm, index, naver_client_id, naver_client_secret

###yyh
from pathlib import Path
import joblib, json

# tools.py íŒŒì¼ì´ ìˆëŠ” í´ë”ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì„¤ì •
BASE_DIR = Path(__file__).resolve().parent
DEFAULT_MODEL_PATH = BASE_DIR / "models.pkl"
DEFAULT_PERFUME_JSON = BASE_DIR / "perfumes.json"
###yyh

parse_prompt = ChatPromptTemplate.from_messages([
    ("system", """ë„ˆëŠ” í–¥ìˆ˜ ì¿¼ë¦¬ íŒŒì„œì•¼.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì¤˜:
- brand: ë¸Œëœë“œëª… (ì˜ˆ: ìƒ¤ë„¬, ë””ì˜¬, ì…ìƒë¡œë‘ ë“±)
- concentration: (í¼í“¸, ì½”ë¡± ë“±)
- day_night_score: ì‚¬ìš©ì‹œê°„ (ì£¼ê°„, ì•¼ê°„, ë°ì¼ë¦¬ ë“±)
- gender: ì„±ë³„ (ë‚¨ì„±, ì—¬ì„±, ìœ ë‹ˆì„¹ìŠ¤)
- season_score: ê³„ì ˆ (ë´„, ì—¬ë¦„, ê°€ì„, ê²¨ìš¸)
- sizes: ìš©ëŸ‰ (30ml, 50ml, 100ml ë“±) ë‹¨ìœ„ëŠ” ë¬´ì‹œí•˜ê³  ìˆ«ìë§Œ

ì—†ëŠ” ê°’ì€ nullë¡œ ë‘ê³ , ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì¤˜.

ì˜ˆì‹œ:
{{"brand": "ìƒ¤ë„¬", "gender": null, "sizes": "50", "season_score": null, "concentration": null, "day_night_score": null}}"""),
    ("user", "{query}")
])

def run_llm_parser(query: str):
    """ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ JSONìœ¼ë¡œ íŒŒì‹±"""
    try:
        chain = parse_prompt | llm
        ai_response = chain.invoke({"query": query})
        response_text = ai_response.content.strip()

        # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
        if "```json" in response_text:
            response_text = response_text.split("```json")[1].split("```")[0].strip()
        elif "```" in response_text:
            response_text = response_text.split("```")[1].strip()

        parsed = json.loads(response_text)
        return parsed
    except Exception as e:
        return {"error": f"íŒŒì‹± ì˜¤ë¥˜: {str(e)}"}

# ë©”íƒ€í•„í„° í•¨ìˆ˜ë“¤
def filter_brand(brand_value):
    valid_brands = [
        'ê²”ë‘', 'êµ¬ì°Œ', 'ëŒë¡œì—', 'ë‚˜ë¥´ì‹œì†Œ ë¡œë“œë¦¬ê²Œì¦ˆ', 'ë‹ˆìƒ¤ë„¤', 'ë„ë¥´ì„¸', 'ë””ì˜¬', 'ë”¥í‹°í¬', 'ë‘ì½¤',
        'ë¡œë¼ ë©”ë¥´ì‹œì—', 'ë¡œì—ë² ', 'ë¡ì‹œë•…', 'ë¥´ ë¼ë³´', 'ë©”ëª¨', 'ë©”ì¢… ë§ˆë¥´ì§€ì—˜ë¼', 'ë©”ì¢… í”„ë€ì‹œìŠ¤ ì»¤ì •',
        'ë©œë¦°ì•¤ê²Œì¸ ', 'ë¯¸ìš°ë¯¸ìš°', 'ë°”ì´ë ˆë„', 'ë°˜í´ë¦¬í”„ ì•„í ', 'ë²„ë²„ë¦¬', 'ë² ë¥´ì‚¬ì²´', 'ë¶ˆê°€ë¦¬', 'ë¹„ë””ì¼€ì´',
        'ì‚°íƒ€ ë§ˆë¦¬ì•„ ë…¸ë²¨ë¼', 'ìƒ¤ë„¬', 'ì„¸ë¥´ì£¼ ë£¨í…', 'ì‹œìŠ¬ë¦¬ ì½”ìŠ¤ë©”í‹±', 'ì•„ì¿ ì•„ ë”” íŒŒë¥´ë§ˆ', 'ì—ë”° ë¦¬ë¸Œë¥´ ë„ëŸ‰ì¥¬',
        'ì—ë¥´ë©”ìŠ¤', 'ì—ìŠ¤í‹° ë¡œë”', 'ì—‘ìŠ¤ ë‹ˆíë¡œ', 'ì´ë‹ˆì‹œì˜¤ í¼í“¸', 'ì´ì†', 'ì…ìƒë¡œë‘', 'ì œë¥´ì¡°í”„', 'ì¡° ë§ë¡ ',
        'ì¡°ë¥´ì§€ì˜¤ ì•„ë¥´ë§ˆë‹ˆ', 'ì¤„ë¦¬ì—£ í—¤ì¦ˆ ì–´ ê±´', 'ì§€ë°©ì‹œ', 'ì§ˆ ìŠ¤íŠœì–´íŠ¸', 'í¬ë¦¬ë“œ', 'í‚¬ë¦¬ì•ˆ', 'í†° í¬ë“œ',
        'í‹°íŒŒë‹ˆì•¤ì½”', 'í¼í“¸ ë“œ ë§ë¦¬', 'íœí• ë¦¬ê³¤ìŠ¤', 'í”„ë¼ë‹¤', 'í”„ë ˆë°ë¦­ ë§'
    ]
    if brand_value is None:
        return None
    return brand_value if brand_value in valid_brands else None

def filter_concentration(concentration_value):
    valid_concentrations = ['ì†”ë¦¬ë“œ í¼í“¸', 'ì—‘ìŠ¤íŠ¸ë ˆ ë“œ í¼í“¸', 'ì˜¤ ë“œ ëšœì™ˆë ›', 'ì˜¤ ë“œ ì½”ë¡±', 'ì˜¤ ë“œ í¼í“¸', 'í¼í“¸']
    if concentration_value is None:
        return None
    return concentration_value if concentration_value in valid_concentrations else None

def filter_day_night_score(day_night_value):
    valid_day_night = ["day", "night"]
    if day_night_value is None:
        return None
    if isinstance(day_night_value, str) and ',' in day_night_value:
        values = [v.strip() for v in day_night_value.split(',')]
        filtered_values = [v for v in values if v in valid_day_night]
        return ','.join(filtered_values) if filtered_values else None
    return day_night_value if day_night_value in valid_day_night else None

def filter_gender(gender_value):
    valid_genders = ['Female', 'Male', 'Unisex', 'unisex ']
    if gender_value is None:
        return None
    return gender_value if gender_value in valid_genders else None

def filter_season_score(season_value):
    valid_seasons = ['winter', 'spring', 'summer', 'fall']
    if season_value is None:
        return None
    return season_value if season_value in valid_seasons else None

def filter_sizes(sizes_value):
    valid_sizes = ['30', '50', '75', '100', '150']
    if sizes_value is None:
        return None
    if isinstance(sizes_value, str):
        numbers = re.findall(r'\d+', sizes_value)
        for num in numbers:
            if num in valid_sizes:
                return num
    return str(sizes_value) if str(sizes_value) in valid_sizes else None

def apply_meta_filters(parsed_json: dict) -> dict:
    """íŒŒì‹±ëœ JSONì— ë©”íƒ€priceë§ ì ìš©"""
    if not parsed_json or "error" in parsed_json:
        return parsed_json
    
    return {
        'brand': filter_brand(parsed_json.get('brand')),
        'concentration': filter_concentration(parsed_json.get('concentration')),
        'day_night_score': filter_day_night_score(parsed_json.get('day_night_score')),
        'gender': filter_gender(parsed_json.get('gender')),
        'season_score': filter_season_score(parsed_json.get('season_score')),
        'sizes': filter_sizes(parsed_json.get('sizes'))
    }

def build_pinecone_filter(filtered_json: dict) -> dict:
    """ë©”íƒ€priceë§ ê²°ê³¼ë¥¼ Pinecone filter dictë¡œ ë³€í™˜"""
    pinecone_filter = {}
    if filtered_json.get("brand"):
        pinecone_filter["brand"] = {"$eq": filtered_json["brand"]}
    if filtered_json.get("sizes"):
        pinecone_filter["sizes"] = {"$eq": filtered_json["sizes"]}
    if filtered_json.get("season_score"):
        pinecone_filter["season_score"] = {"$eq": filtered_json["season_score"]}
    if filtered_json.get("gender"):
        pinecone_filter["gender"] = {"$eq": filtered_json["gender"]}
    if filtered_json.get("concentration"):
        pinecone_filter["concentration"] = {"$eq": filtered_json["concentration"]}
    if filtered_json.get("day_night_score"):
        pinecone_filter["day_night_score"] = {"$eq": filtered_json["day_night_score"]}
    return pinecone_filter

# í‚¤ì›Œë“œ ì •ì œìš© í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì¶”ê°€
keyword_extraction_prompt = ChatPromptTemplate.from_messages([
    ("system", """ë„ˆëŠ” ë„¤ì´ë²„ ì‡¼í•‘ ê²€ìƒ‰ìš© í‚¤ì›Œë“œ ì¶”ì¶œ ì „ë¬¸ê°€ì•¼.

ì‚¬ìš©ìì˜ í–¥ìˆ˜ ê°€ê²© ì§ˆë¬¸ì—ì„œ ë„¤ì´ë²„ ì‡¼í•‘ API ê²€ìƒ‰ì— ìµœì í™”ëœ í‚¤ì›Œë“œë§Œ ì¶”ì¶œí•´ì¤˜.

**ì¶”ì¶œ ê·œì¹™:**
1. ë¸Œëœë“œëª…ê³¼ ì œí’ˆëª…ë§Œ ì¶”ì¶œ (í•œêµ­ì–´ ìš°ì„ )
2. ê°€ê²© ê´€ë ¨ ë‹¨ì–´ë“¤ì€ ëª¨ë‘ ì œê±° (ê°€ê²©, ì–¼ë§ˆ, ìµœì €ê°€, í• ì¸, ì–´ë””ì„œ, ì‚¬ëŠ”, êµ¬ë§¤ ë“±)
3. ì§ˆë¬¸ í˜•íƒœ ë‹¨ì–´ë“¤ë„ ì œê±° (?, ì•¼, ê²Œ, ì¤˜, ì•Œë ¤, ë­, ì–´ë–¤ ë“±)
4. ìµœëŒ€ 2-3ê°œ ë‹¨ì–´ë¡œ ê°„ê²°í•˜ê²Œ
5. í–¥ìˆ˜ ë¸Œëœë“œëª…ê³¼ ì œí’ˆëª…ì´ ëª…í™•í•˜ë©´ "ë¸Œëœë“œ ì œí’ˆëª…" í˜•íƒœë¡œ
6. ë¸Œëœë“œëª…ë§Œ ìˆìœ¼ë©´ "ë¸Œëœë“œëª…" ë§Œ
7. ì• ë§¤í•˜ë©´ "í–¥ìˆ˜" í‚¤ì›Œë“œ ì‚¬ìš©

**ì˜ˆì‹œ:**
- "ë””ì˜¬ ì†Œë°”ì¥¬ ê°€ê²© ì–¼ë§ˆì•¼?" â†’ "ë””ì˜¬ ì†Œë°”ì¥¬"  
- "ìƒ¤ë„¬ ë„˜ë²„5 50ml ì–´ë””ì„œ ì‚¬?" â†’ "ìƒ¤ë„¬ ë„˜ë²„5"
- "í†°í¬ë“œ í–¥ìˆ˜ ìµœì €ê°€ ì•Œë ¤ì¤˜" â†’ "í†°í¬ë“œ í–¥ìˆ˜"
- "í–¥ìˆ˜ ê°€ê²© ì•Œë ¤ì¤˜" â†’ "í–¥ìˆ˜"

ë°˜ë“œì‹œ ê²€ìƒ‰ í‚¤ì›Œë“œë§Œ ì‘ë‹µí•˜ê³  ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ë§ˆ."""),
    ("user", "{query}")
])

@tool
def price_tool(user_query: str) -> str:
    """A tool that uses the Naver Shopping API to look up perfume prices (results are returned as formatted strings)"""
    
    # LLMìœ¼ë¡œ ê²€ìƒ‰ í‚¤ì›Œë“œ ì¶”ì¶œ
    search_keyword = extract_search_keyword_with_llm(user_query)
    
    url = "https://openapi.naver.com/v1/search/shop.json"
    headers = {
        "X-Naver-Client-Id": naver_client_id,
        "X-Naver-Client-Secret": naver_client_secret
    }
    params = {"query": search_keyword, "display": 5, "sort": "sim"}
    
    try:
        response = requests.get(url, headers=headers, params=params)
    except Exception as e:
        return f"âŒ ìš”ì²­ ì˜¤ë¥˜: {e}"
    
    if response.status_code != 200:
        return f"âŒ API ì˜¤ë¥˜: {response.status_code}"
    
    data = response.json()
    if not data or "items" not in data or len(data["items"]) == 0:
        return f"ğŸ˜” '{search_keyword}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\nğŸ’¡ ë‹¤ë¥¸ ë¸Œëœë“œëª…ì´ë‚˜ í–¥ìˆ˜ëª…ìœ¼ë¡œ ë‹¤ì‹œ ê²€ìƒ‰í•´ë³´ì„¸ìš”."
    
    # HTML íƒœê·¸ ì œê±° í•¨ìˆ˜
    def remove_html_tags(text: str) -> str:
        return re.sub(r"<[^>]+>", "", text)
    
    # ìƒìœ„ 3ê°œë§Œ ì •ë¦¬
    products = data["items"][:1]
    output = f"ğŸ” '{search_keyword}' ê²€ìƒ‰ ê²°ê³¼:\n\n"
    
    prices = []  # ê°€ê²© ì •ë³´ ìˆ˜ì§‘ìš©
    
    for i, item in enumerate(products, 1):
        title = remove_html_tags(item.get("title", ""))
        lprice = item.get("lprice", "0")
        mall = item.get("mallName", "ì •ë³´ ì—†ìŒ")
        link = item.get("link", "ì •ë³´ ì—†ìŒ")
        
        output += f"ğŸ“¦ {i}. {title}\n"
        if lprice != "0":
            formatted_price = f"{int(lprice):,}ì›"
            output += f"   ğŸ’° ê°€ê²©: {formatted_price}\n"
            prices.append(int(lprice))
        output += f"   ğŸª íŒë§¤ì²˜: {mall}\n"
        output += f"   ğŸ”— ë§í¬: {link}\n\n"
    
    # ê°€ê²© ë²”ìœ„ ì •ë³´ ì¶”ê°€ (ìµœì €ê°€/ìµœê³ ê°€ ëŒ€ì‹  ê°€ê²©ëŒ€ ì •ë³´ ì œê³µ)
    if prices:
        min_price = min(prices)
        max_price = max(prices)
        if len(prices) > 1:
            output += f"ğŸ’¡ **ê°€ê²©ëŒ€ ì •ë³´**\n"
            output += f"   ğŸ“Š ê²€ìƒ‰ëœ ê°€ê²© ë²”ìœ„: {min_price:,}ì› ~ {max_price:,}ì›\n"
            output += f"   âš ï¸ ì •í™•í•œ ìµœì €ê°€/ìµœê³ ê°€ ì •ë³´ëŠ” ê° ì‡¼í•‘ëª°ì—ì„œ ì§ì ‘ í™•ì¸í•´ì£¼ì„¸ìš”.\n"
        else:
            output += f"ğŸ’¡ **ì°¸ê³ ì‚¬í•­**\n"
            output += f"   âš ï¸ ë” ë§ì€ ê°€ê²© ë¹„êµë¥¼ ì›í•˜ì‹œë©´ ì—¬ëŸ¬ ì‡¼í•‘ëª°ì„ ì§ì ‘ í™•ì¸í•´ë³´ì„¸ìš”.\n"
    
    return output

def extract_search_keyword_with_llm(user_query: str) -> str:
    """LLMì„ ì‚¬ìš©í•´ì„œ ê²€ìƒ‰ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    try:
        chain = keyword_extraction_prompt | llm
        response = chain.invoke({"query": user_query})
        keyword = response.content.strip()
        
        # ë¹ˆ ì‘ë‹µì´ê±°ë‚˜ ë„ˆë¬´ ê¸´ ê²½ìš° ê¸°ë³¸ê°’ ë°˜í™˜
        if not keyword or len(keyword) > 20:
            return "í–¥ìˆ˜"
        
        return keyword
    except Exception as e:
        print(f"í‚¤ì›Œë“œ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return "í–¥ìˆ˜"  # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’


@tool
def recommend_perfume_simple(
    user_text: str,
    topk_labels: int = 4,
    top_n_perfumes: int = 5,
    use_thresholds: bool = True,
    # model_pkl_path: str = "./models.pkl",
    # perfume_json_path: str = "perfumes.json",
    model_pkl_path: str = str(DEFAULT_MODEL_PATH),      # ìˆ˜ì •
    perfume_json_path: str = str(DEFAULT_PERFUME_JSON), # ìˆ˜ì •

    model_name: str = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
    max_len: int = 256,
):
    """
    Minimal one-shot perfume recommender (no caching).
    Loads model & data every call, predicts labels, retrieves with BM25, and returns a JSON-serializable dict.
    """
    device = "cuda" if torch.cuda.is_available() else "cpu"

    # 1) Load ML bundle
    data = joblib.load(model_pkl_path)
    clf = data["classifier"]
    mlb = data["mlb"]
    thresholds = data.get("thresholds", {}) or {}

    # 2) Encoder
    tok = AutoTokenizer.from_pretrained(model_name)
    enc_model = AutoModel.from_pretrained(model_name).to(device)
    enc_model.eval()

    # 3) Load perfumes
    with open(perfume_json_path, "r", encoding="utf-8") as f:
        perfumes = json.load(f)
        if not isinstance(perfumes, list):
            raise ValueError("perfumes.json must contain a list of perfume objects")

    # 4) BM25 index (simple: use 'fragrances' or fallback to description/name/brand)
    def doc_of(p):
        fr = p.get("fragrances")
        if isinstance(fr, list):
            text = " ".join(map(str, fr))
        elif isinstance(fr, str):
            text = fr
        else:
            text = " ".join(
                str(x)
                for x in [
                    p.get("description", ""),
                    p.get("main_accords", ""),
                    p.get("name_perfume") or p.get("name", ""),
                    p.get("brand", ""),
                ]
                if x
            )
        return (text or "unknown").lower()

    tokenized_corpus = [doc_of(p).split() for p in perfumes]
    bm25 = BM25Okapi(tokenized_corpus)

    # 5) Encode text -> vector
    batch = tok(
        [user_text],
        padding=True,
        truncation=True,
        max_length=max_len,
        return_tensors="pt",
    ).to(device)
    with torch.no_grad():
        out = enc_model(**batch)
        emb = out.last_hidden_state.mean(dim=1).cpu().numpy()  # ultra-simple mean

    # 6) Predict labels (supports predict_proba / decision_function / predict)
    if hasattr(clf, "predict_proba"):
        proba = clf.predict_proba(emb)[0]
    elif hasattr(clf, "decision_function"):
        logits = np.asarray(clf.decision_function(emb)[0], dtype=float)
        proba = 1.0 / (1.0 + np.exp(-logits))
    else:
        proba = np.asarray(clf.predict(emb)[0], dtype=float)

    classes = list(mlb.classes_)
    if use_thresholds and thresholds:
        picked_idx = [i for i, p in enumerate(proba) if p >= float(thresholds.get(classes[i], 0.5))]
        if not picked_idx:
            picked_idx = np.argsort(-proba)[:topk_labels].tolist()
    else:
        picked_idx = np.argsort(-proba)[:topk_labels].tolist()

    labels = [classes[i] for i in picked_idx]

    # 7) Retrieve with BM25
    scores = bm25.get_scores(" ".join(labels).split())
    top_idx = np.argsort(scores)[-top_n_perfumes:][::-1]

    def _safe(d, *keys, default="N/A"):
        for k in keys:
            if k in d and d[k] not in (None, ""):
                return d[k]
        return default

    recs = []
    for rnk, idx in enumerate(top_idx, 1):
        p = perfumes[int(idx)]
        fr = p.get("fragrances")
        if isinstance(fr, list):
            fr_text = ", ".join(map(str, fr))
        else:
            fr_text = fr if isinstance(fr, str) else _safe(p, "main_accords", default="N/A")
        recs.append({
            "rank": int(rnk),
            "index": int(idx),
            "score": float(scores[int(idx)]),
            "brand": _safe(p, "brand"),
            "name": _safe(p, "name_perfume", "name"),
            "fragrances": fr_text,
            "perfume_data": p,  # JSON-native
        })

    return {
        "user_input": user_text,
        "predicted_labels": labels,
        "recommendations": recs,
        "meta": {
            "model_name": model_name,
            "device": device,
            "max_len": int(max_len),
            "db_size": int(len(perfumes)),
        },
    }

def query_pinecone(vector, filtered_json: dict, top_k: int = 5):
    """Pinecone ë²¡í„° ê²€ìƒ‰ + ë©”íƒ€ë°ì´í„° price ì ìš©"""
    pinecone_filter = build_pinecone_filter(filtered_json)
    
    result = index.query(
        vector=vector,
        top_k=top_k,
        include_metadata=True,
        filter=pinecone_filter if pinecone_filter else None
    )
    return result

response_prompt = ChatPromptTemplate.from_messages([
    ("system", """ë„ˆëŠ” í–¥ìˆ˜ ì „ë¬¸ê°€ì•¼. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ê²€ìƒ‰ëœ í–¥ìˆ˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ ì¶”ì²œì„ í•´ì¤˜.

ì¶”ì²œí•  ë•Œ ë‹¤ìŒì„ í¬í•¨í•´ì¤˜:
1. ì™œ ì´ í–¥ìˆ˜ë¥¼ ì¶”ì²œí•˜ëŠ”ì§€
2. í–¥ì˜ íŠ¹ì§•ê³¼ ëŠë‚Œ
3. ì–´ë–¤ ìƒí™©ì— ì í•©í•œì§€
4. ê°€ê²©ëŒ€ë‚˜ ìš©ëŸ‰ ê´€ë ¨ ì¡°ì–¸ (ìˆë‹¤ë©´)

ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ í†¤ìœ¼ë¡œ ë‹µë³€í•´ì¤˜."""),
    ("user", """ì‚¬ìš©ì ì§ˆë¬¸: {original_query}

ê²€ìƒ‰ëœ í–¥ìˆ˜ ì •ë³´:
{search_results}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í–¥ìˆ˜ë¥¼ ì¶”ì²œí•´ì¤˜.""")
])

def format_search_results(pinecone_results):
    """Pinecone ê²€ìƒ‰ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…"""
    if not pinecone_results or not pinecone_results.get('matches'):
        return "ê²€ìƒ‰ëœ í–¥ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    formatted_results = []
    for i, match in enumerate(pinecone_results['matches'], 1):
        metadata = match.get('metadata', {})
        score = match.get('score', 0)
        
        result_text = f"""
{i}. í–¥ìˆ˜ëª…: {metadata.get('perfume_name', 'ì •ë³´ì—†ìŒ')}
   - ë¸Œëœë“œ: {metadata.get('brand', 'ì •ë³´ì—†ìŒ')}
   - ì„±ë³„: {metadata.get('gender', 'ì •ë³´ì—†ìŒ')}
   - ìš©ëŸ‰: {metadata.get('sizes', 'ì •ë³´ì—†ìŒ')}ml
   - ê³„ì ˆ: {metadata.get('season_score', 'ì •ë³´ì—†ìŒ')}
   - ì‚¬ìš©ì‹œê°„: {metadata.get('day_night_score', 'ì •ë³´ì—†ìŒ')}
   - ë†ë„: {metadata.get('concentration', 'ì •ë³´ì—†ìŒ')}
   - ìœ ì‚¬ë„ ì ìˆ˜: {score:.3f}
"""
        formatted_results.append(result_text.strip())
    
    return "\n\n".join(formatted_results)

def generate_response(original_query: str, search_results):
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì‘ë‹µ ìƒì„±"""
    try:
        formatted_results = format_search_results(search_results)
        
        chain = response_prompt | llm
        response = chain.invoke({
            "original_query": original_query,
            "search_results": formatted_results
        })
        
        return response.content
    except Exception as e:
        return f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
def extract_price_search_keywords(search_results, original_query: str, parsed_json: dict) -> str:
    """
    ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì‹¤ì œ í–¥ìˆ˜ ì œí’ˆëª…ì„ ì¶”ì¶œí•˜ì—¬ ê°€ê²© ê²€ìƒ‰ í‚¤ì›Œë“œë¡œ ì‚¬ìš©
    """
    # 1. ê²€ìƒ‰ ê²°ê³¼ì—ì„œ í–¥ìˆ˜ëª… ì¶”ì¶œ (ìµœìƒìœ„ 1ê°œ)
    if search_results and search_results.get('matches'):
        top_match = search_results['matches'][0]  # ê°€ì¥ ìœ ì‚¬ë„ ë†’ì€ í–¥ìˆ˜
        metadata = top_match.get('metadata', {})
        
        perfume_name = metadata.get('perfume_name', '')
        brand_name = metadata.get('brand', '')
        
        if perfume_name and brand_name:
            # "ë¸Œëœë“œ + í–¥ìˆ˜ëª…" ì¡°í•©ìœ¼ë¡œ êµ¬ì²´ì ì¸ ê²€ìƒ‰
            search_keyword = f"{brand_name} {perfume_name}"
            
            # ìš©ëŸ‰ ì •ë³´ ì¶”ê°€ (ìˆë‹¤ë©´)
            sizes = parsed_json.get('sizes')
            if sizes:
                search_keyword += f" {sizes}ml"
            
            return search_keyword
        
        elif perfume_name:
            # í–¥ìˆ˜ëª…ë§Œ ìˆëŠ” ê²½ìš°
            sizes = parsed_json.get('sizes')
            if sizes:
                return f"{perfume_name} {sizes}ml"
            return perfume_name
        
        elif brand_name:
            # ë¸Œëœë“œëª…ë§Œ ìˆëŠ” ê²½ìš°
            sizes = parsed_json.get('sizes')
            if sizes:
                return f"{brand_name} í–¥ìˆ˜ {sizes}ml"
            return f"{brand_name} í–¥ìˆ˜"
    
    # 2. ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ë©”íƒ€ë°ì´í„°ê°€ ë¶€ì¡±í•œ ê²½ìš° íŒŒì‹± ê²°ê³¼ ì‚¬ìš©
    brand = parsed_json.get('brand')
    sizes = parsed_json.get('sizes')
    
    if brand:
        if sizes:
            return f"{brand} í–¥ìˆ˜ {sizes}ml"
        return f"{brand} í–¥ìˆ˜"
    
    # 3. ëª¨ë“  ì •ë³´ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
    return "í–¥ìˆ˜"

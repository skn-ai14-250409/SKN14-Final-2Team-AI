# --- stdlib ---
import json
import os
# --- typing ---
from typing import TypedDict, List, Optional, Dict, Any

# --- env ---
from dotenv import load_dotenv
# from config import llm, embeddings, index, MODEL_NAME, pc
from .config import llm, embeddings, index, MODEL_NAME, pc # yyh


# --- langchain / langgraph ---
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langgraph.graph import StateGraph, END

# --- services (ì¿¼ë¦¬ íŒŒì‹±/í•„í„°/ê²€ìƒ‰/ì‘ë‹µ/ê°€ê²© í‚¤ì›Œë“œ) ---
# from tools import run_llm_parser
# from tools import apply_meta_filters
# from tools import query_pinecone
# from tools import generate_response
# from tools import extract_price_search_keywords
from .tools import run_llm_parser
from .tools import apply_meta_filters
from .tools import query_pinecone
from .tools import generate_response
from .tools import extract_price_search_keywords


# --- tools (Naver ê°€ê²©/ML ì¶”ì²œ) ---
# from tools import price_tool, recommend_perfume_simple
from .tools import price_tool, recommend_perfume_simple
load_dotenv()


SUPERVISOR_SYSTEM_PROMPT = """
You are the "Perfume Recommendation Supervisor (Router)". Analyze the user's query (Korean or English) and route to exactly ONE agent below.

[Agents]
- LLM_parser         : Parses/normalizes multi-facet queries (2+ product facets).
- FAQ_agent          : Perfume knowledge / definitions / differences / general questions.
- human_fallback     : Non-perfume or off-topic queries.
- price_agent        : Price-only intents (cheapest, price, buy, discount, etc.).
- ML_agent           : Single-preference recommendations (mood/season vibe like "fresh summer", "sweet", etc.).

[Facets to detect ("product facets")]
- brand            (e.g., Chanel, Dior, Creed)
- season           (spring/summer/fall/winter; "for summer/winter")
- gender           (male/female/unisex)
- sizes            (volume in ml: 30/50/100 ml)
- day_night_score  (day/night/daily/office/club, etc.)
- concentration    (EDT/EDP/Extrait/Parfum/Cologne)

[Price intent keywords (not exhaustive)]
- Korean: ê°€ê²©, ì–¼ë§ˆ, ê°€ê²©ëŒ€, êµ¬ë§¤, íŒë§¤, í• ì¸, ì–´ë””ì„œ ì‚¬, ë°°ì†¡ë¹„
- English: price, cost, cheapest, buy, purchase, discount

[FAQ examples]
- Differences between EDP vs EDT, note definitions, longevity/projection, brand/line info.

[Single-preference (ML_agent) examples]
- "Recommend a cool perfume for summer", "Recommend a sweet scent", "One citrusy fresh pick"
  (= 0â€“1 of the above facets mentioned; primarily taste/mood/situation).


[Routing rules (priority)]
1) Non-perfume / off-topic â†’ human_fallback
2) Pure price-only intent (no product facets mentioned) â†’ price_agent
   e.g., "í–¥ìˆ˜ ê°€ê²© ì•Œë ¤ì¤˜" â†’ price_agent
3) Count product facets in the query:
   - If facets â‰¥ 2 â†’ LLM_parser (can handle price intent within multi-facet queries)
   - If facets = 1 AND has price intent â†’ LLM_parser (e.g., "ìƒ¤ë„¬ í–¥ìˆ˜ ê°€ê²©")
4) Otherwise (single-topic queries):
   - Pure price query with specific brand/product â†’ price_agent
   - Perfume knowledge/definitions â†’ FAQ_agent
   - Single taste/mood recommendation â†’ ML_agent
5) Tie-breakers:
   - If complex query (multiple aspects) â†’ LLM_parser
   - If pure price intent â†’ price_agent
   - Else: knowledge â†’ FAQ_agent, taste â†’ ML_agent

[Output format]
Return ONLY this JSON (no extra text):
{{
  "next": "<LLM_parser|FAQ_agent|human_fallback|price_agent|ML_agent>",
  "reason": "<one short English sentence>",
  "facet_count": <integer>,
  "facets": {{
    "brand": "<value or null>",
    "season": "<value or null>",
    "gender": "<value or null>",
    "sizes": "<value or null>",
    "day_night_score": "<value or null>",
    "concentration": "<value or null>"
  }},
  "scent_vibe": "<value if detected, else null>",
  "query_intent": "<price|faq|scent_pref|non_perfume|other>"
}}
""".strip()

# ---------- 1) State ----------
class AgentState(TypedDict):
    messages: List[BaseMessage]           # conversation log
    next: Optional[str]                   # routing decision key 
    router_json: Optional[Dict[str, Any]] # parsed JSON from router

router_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", SUPERVISOR_SYSTEM_PROMPT),
        ("user", "{query}")
    ]
)

def supervisor_node(state: AgentState) -> AgentState:
    """Call the router LLM and return parsed JSON + routing target."""
    user_query = None
    for m in reversed(state["messages"]):
        if isinstance(m, HumanMessage):
            user_query = m.content
            break
    if not user_query:
        user_query = "(empty)"

    chain = router_prompt | llm
    ai = chain.invoke({"query": user_query})
    text = ai.content

    # JSON strict parse
    chosen = "human_fallback"
    parsed: Dict[str, Any] = {}
    try:
        parsed = json.loads(text)
        maybe = parsed.get("next")
        if isinstance(maybe, str) and maybe in {"LLM_parser","FAQ_agent","human_fallback","price_agent","ML_agent"}:
            chosen = maybe
    except Exception:
        parsed = {"error": "invalid_json", "raw": text}

    msgs = state["messages"] + [AIMessage(content=text)]
    return {
        "messages": msgs,
        "next": chosen,
        "router_json": parsed
    }

# ---------- 4) Agent Nodes ----------
import re, json

BRAND_ALIASES = {
    # í•„ìš”ì‹œ ê³„ì† ì¶”ê°€
    "ì…ìƒë¡œë‘": ["ì…ìƒë¡œë‘", "ì´ë¸Œìƒë¡œë‘", "ì´ë¸Œ ìƒ ë¡œë‘", "ìƒë¡œë‘", "YSL", "Yves Saint Laurent"],
}


BRAND_LIST = [
    'ê²”ë‘', 'êµ¬ì°Œ', 'ëŒë¡œì—', 'ë‚˜ë¥´ì‹œì†Œ ë¡œë“œë¦¬ê²Œì¦ˆ', 'ë‹ˆìƒ¤ë„¤', 'ë„ë¥´ì„¸', 'ë””ì˜¬', 'ë”¥í‹°í¬', 'ë‘ì½¤',
    'ë¡œë¼ ë©”ë¥´ì‹œì—', 'ë¡œì—ë² ', 'ë¡ì‹œë•…', 'ë¥´ ë¼ë³´', 'ë©”ëª¨', 'ë©”ì¢… ë§ˆë¥´ì§€ì—˜ë¼', 'ë©”ì¢… í”„ë€ì‹œìŠ¤ ì»¤ì •',
    'ë©œë¦°ì•¤ê²Œì¸ ', 'ë¯¸ìš°ë¯¸ìš°', 'ë°”ì´ë ˆë„', 'ë°˜í´ë¦¬í”„ ì•„í ', 'ë²„ë²„ë¦¬', 'ë² ë¥´ì‚¬ì²´', 'ë¶ˆê°€ë¦¬', 'ë¹„ë””ì¼€ì´',
    'ì‚°íƒ€ ë§ˆë¦¬ì•„ ë…¸ë²¨ë¼', 'ìƒ¤ë„¬', 'ì„¸ë¥´ì£¼ ë£¨í…', 'ì‹œìŠ¬ë¦¬ ì½”ìŠ¤ë©”í‹±', 'ì•„ì¿ ì•„ ë”” íŒŒë¥´ë§ˆ', 'ì—ë”° ë¦¬ë¸Œë¥´ ë„ëŸ‰ì¥¬',
    'ì—ë¥´ë©”ìŠ¤', 'ì—ìŠ¤í‹° ë¡œë”', 'ì—‘ìŠ¤ ë‹ˆíë¡œ', 'ì´ë‹ˆì‹œì˜¤ í¼í“¸', 'ì´ì†', 'ì…ìƒë¡œë‘', 'ì œë¥´ì¡°í”„', 'ì¡° ë§ë¡ ',
    'ì¡°ë¥´ì§€ì˜¤ ì•„ë¥´ë§ˆë‹ˆ', 'ì¤„ë¦¬ì—£ í—¤ì¦ˆ ì–´ ê±´', 'ì§€ë°©ì‹œ', 'ì§ˆ ìŠ¤íŠœì–´íŠ¸', 'í¬ë¦¬ë“œ', 'í‚¬ë¦¬ì•ˆ', 'í†° í¬ë“œ',
    'í‹°íŒŒë‹ˆì•¤ì½”', 'í¼í“¸ ë“œ ë§ë¦¬', 'íœí• ë¦¬ê³¤ìŠ¤', 'í”„ë¼ë‹¤', 'í”„ë ˆë°ë¦­ ë§'
]

CONC_SYNONYMS = {
    "ì˜¤ ë“œ í¼í“¸": ["ì˜¤ ë“œ í¼í“¸", "ì˜¤ë“œí¼í“¸", "EDP", "eau de parfum"],
    "ì˜¤ ë“œ ëšœì™ˆë ›": ["ì˜¤ ë“œ ëšœì™ˆë ›", "ì˜¤ë“œëšœì™ˆë ›", "EDT", "eau de toilette"],
    "ì˜¤ ë“œ ê¼´ë¡œë‰´": ["ì˜¤ ë“œ ê¼´ë¡œë‰´", "EDC", "eau de cologne"],
    "íŒŒë¥´í­": ["íŒŒë¥´í­", "Parfum", "Extrait", "Extrait de Parfum"],
}

def _normalize_size(size_val):
    """'50' -> '50ml', '50 ml' -> '50ml'"""
    if not size_val:
        return None
    s = str(size_val).strip().lower().replace(" ", "")
    if s.endswith("ml"):
        return s
    if re.fullmatch(r"\d{1,4}", s):
        return s + "ml"
    return s

def _expand_brand(brand):
    if not brand:
        return []
    return BRAND_ALIASES.get(brand, [brand])

def _expand_concentration(conc):
    if not conc:
        return []
    c = str(conc)
    for k, syns in CONC_SYNONYMS.items():
        if k.replace(" ", "") in c.replace(" ", "") or c in syns:
            return syns
    return [c]

def _extract_matches(search_results: dict):
    """Pinecone matches -> list of metadata dict"""
    matches = (search_results or {}).get("matches") or []
    return [m.get("metadata") or {} for m in matches]

def _make_display_name(meta, size=None):
    brand = (meta.get("brand") or "").strip()
    name  = (meta.get("name") or "").strip()
    conc  = (meta.get("concentration") or "").strip()
    toks = [brand, name, conc, size]
    return " ".join([t for t in toks if t])

def build_item_queries_from_vectordb(
    search_results: dict,
    facets: dict | None = None,
    top_n_items: int = 5,
) -> list[dict]:
    """
    ë°˜í™˜: [{item_label, queries}] ë¦¬ìŠ¤íŠ¸
    - item_label: ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ë¼ë²¨(brand name conc size)
    - queries: ì´ ì•„ì´í…œë§Œì„ ê²¨ëƒ¥í•œ ë„¤ì´ë²„ ê²€ìƒ‰ í›„ë³´ë“¤(ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸)
    (â€» ë¸Œëœë“œ+ì œí’ˆëª… í•„ìˆ˜. ë‹¤ë¥¸ ì œí’ˆìœ¼ë¡œ ìƒ ì—¬ì§€ë¥¼ ìµœì†Œí™”)
    """
    facets = facets or {}
    target_size = _normalize_size(facets.get("sizes"))
    metas = _extract_matches(search_results)[:top_n_items]

    results = []
    seen_items = set()  # (brand|name)ë¡œ ì¤‘ë³µ ì œê±°

    for meta in metas:
        brand = meta.get("brand")
        name  = meta.get("name")
        conc  = meta.get("concentration")
        sizes = meta.get("sizes")

        if not brand or not name:
            continue

        key = f"{brand}|{name}"
        if key in seen_items:
            continue
        seen_items.add(key)

        size_for_query = target_size
        if not size_for_query:
            if isinstance(sizes, (list, tuple)) and sizes:
                if "50" in sizes or "50ml" in sizes:
                    size_for_query = "50ml"
                else:
                    size_for_query = _normalize_size(sizes[0])

        brand_variants = _expand_brand(brand)
        conc_variants  = _expand_concentration(conc) if conc else []

        def join(*toks): return " ".join([t for t in toks if t and str(t).strip()])
        qs = []

        # A. ë¸Œëœë“œ + ì œí’ˆëª… + ë†ë„ + ì‚¬ì´ì¦ˆ
        if brand_variants and name and conc_variants and size_for_query:
            for b in brand_variants:
                for c in conc_variants:
                    qs.append(join(b, name, c, size_for_query))

        # B. ë¸Œëœë“œ + ì œí’ˆëª… + ì‚¬ì´ì¦ˆ
        if brand_variants and name and size_for_query:
            for b in brand_variants:
                qs.append(join(b, name, size_for_query))

        # C. ë¸Œëœë“œ + ì œí’ˆëª… (ë°±ì—…)
        if brand_variants and name:
            for b in brand_variants:
                qs.append(join(b, name))

        # ì¤‘ë³µ ì œê±°
        seen, deduped = set(), []
        for q in qs:
            if q not in seen:
                seen.add(q)
                deduped.append(q)

        results.append({
            "item_label": _make_display_name(meta, size_for_query),
            "queries": deduped[:6],
        })

    return results


# ========= LLM_parser_node (ê°€ê²© ê²€ìƒ‰ íŒŒíŠ¸: vectorDB ì•„ì´í…œë§Œ ì‚¬ìš©) =========
def LLM_parser_node(state: AgentState) -> AgentState:
    """ì‹¤ì œ RAG íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ëŠ” LLM_parser ë…¸ë“œ + ê°€ê²© ê²€ìƒ‰(ë²¡í„°DB í•œì •) í†µí•©"""
    user_query = None
    for m in reversed(state["messages"]):
        if isinstance(m, HumanMessage):
            user_query = m.content
            break
    if not user_query:
        user_query = "(empty)"

    try:
        print(f"ğŸ” LLM_parser ì‹¤í–‰: {user_query}")
        
        # 1ë‹¨ê³„: LLMìœ¼ë¡œ ì¿¼ë¦¬ íŒŒì‹±
        parsed_json = run_llm_parser(user_query)
        if "error" in parsed_json:
            error_msg = f"[LLM_parser] ì¿¼ë¦¬ íŒŒì‹± ì˜¤ë¥˜: {parsed_json['error']}"
            msgs = state["messages"] + [AIMessage(content=error_msg)]
            return {"messages": msgs, "next": None, "router_json": state.get("router_json")}
        
        # 2ë‹¨ê³„: ë©”íƒ€í•„í„° ì ìš©
        filtered_json = apply_meta_filters(parsed_json)
        
        # 3ë‹¨ê³„: ì¿¼ë¦¬ ë²¡í„°í™”
        query_vector = embeddings.embed_query(user_query)
        
        # 4ë‹¨ê³„: Pinecone ê²€ìƒ‰
        search_results = query_pinecone(query_vector, filtered_json, top_k=5)
        
        # 5ë‹¨ê³„: ìµœì¢… ì‘ë‹µ ìƒì„±
        final_response = generate_response(user_query, search_results)
        
        # 6ë‹¨ê³„: ê°€ê²© ì˜ë„ ê°ì§€
        price_keywords_ko = ['ê°€ê²©', 'ì–¼ë§ˆ', 'ê°€ê²©ëŒ€', 'êµ¬ë§¤', 'íŒë§¤', 'í• ì¸', 'ì–´ë””ì„œ ì‚¬', 'ì–´ë””ì„œì‚¬', 'ë°°ì†¡ë¹„', 'ìµœì €ê°€']
        price_keywords_en = ['price', 'cost', 'cheapest', 'buy', 'purchase', 'discount']
        lower = user_query.lower()
        has_price_intent = any(k in user_query for k in price_keywords_ko) or any(k in lower for k in price_keywords_en)
        
        if has_price_intent:
            # ğŸ”’ vectorDBì—ì„œ ê²€ìƒ‰ëœ ì•„ì´í…œë§Œìœ¼ë¡œ ê°€ê²© ì¿¼ë¦¬ ìƒì„±
            item_query_bundles = build_item_queries_from_vectordb(
                search_results=search_results,
                facets=parsed_json,
                top_n_items=5
            )
            print("ğŸ’° ê°€ê²© ê²€ìƒ‰(ë²¡í„°DB í•œì •) ëŒ€ìƒ:")
            for b in item_query_bundles:
                print(f" - {b['item_label']} :: {b['queries'][:3]}")

            price_sections = []
            for bundle in item_query_bundles:
                label = bundle["item_label"]
                queries = bundle["queries"]
                found_block = None

                for q in queries:
                    try:
                        res = price_tool.invoke({"user_query": q})
                        if res:  # í•„ìš”ì‹œ res í¬ë§·ì— ë§ì¶˜ ìœ íš¨ì„± ê²€ì‚¬ ì¶”ê°€
                            found_block = f"ğŸ” **{label}**\n(ê²€ìƒ‰ì–´: `{q}`)\n{res}"
                            break
                    except Exception as price_error:
                        print(f"âŒ ê°€ê²© ê²€ìƒ‰ ì˜¤ë¥˜({q}): {price_error}")
                        continue

                if found_block:
                    price_sections.append(found_block)

            if price_sections:
                final_response_with_price = f"""{final_response}

---

ğŸ’° **ê°€ê²© ì •ë³´ (vectorDB ì¶”ì²œë§Œ)**
{'\n\n'.join(price_sections)}"""
            else:
                final_response_with_price = f"""{final_response}

---

ğŸ’° **ê°€ê²© ì •ë³´ (vectorDB ì¶”ì²œë§Œ)**
ğŸ” ë²¡í„°DBì—ì„œ ì¶”ì²œëœ ì œí’ˆëª…ìœ¼ë¡œ ê²€ìƒ‰í–ˆì§€ë§Œ, ì¼ì¹˜ ê²°ê³¼ë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”.
ì›í•˜ì‹œëŠ” **ì œí’ˆëª… + ë†ë„ + ìš©ëŸ‰(ì˜ˆ: 50ml)** ì¡°í•©ìœ¼ë¡œ ë‹¤ì‹œ ì•Œë ¤ì£¼ì„¸ìš”."""
        else:
            final_response_with_price = final_response
        
        # ê²°ê³¼ ìš”ì•½
        summary = f"""[LLM_parser] RAG íŒŒì´í”„ë¼ì¸ ì™„ë£Œ âœ…

ğŸ“Š íŒŒì‹± ê²°ê³¼: {json.dumps(parsed_json, ensure_ascii=False)}
ğŸ” í•„í„°ë§ ê²°ê³¼: {json.dumps(filtered_json, ensure_ascii=False)}
ğŸ¯ ê²€ìƒ‰ëœ í–¥ìˆ˜ ê°œìˆ˜: {len(search_results.get('matches', []))}

ğŸ’¬ ì¶”ì²œ ê²°ê³¼:
{final_response_with_price}"""

        msgs = state["messages"] + [AIMessage(content=summary)]
        return {"messages": msgs, "next": None, "router_json": state.get("router_json")}
        
    except Exception as e:
        error_msg = f"[LLM_parser] RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}"
        print(f"âŒ LLM_parser ì „ì²´ ì˜¤ë¥˜: {e}")
        msgs = state["messages"] + [AIMessage(content=error_msg)]
        return {"messages": msgs, "next": None, "router_json": state.get("router_json")}
    
    
def human_fallback_node(state: AgentState) -> AgentState:
    """í–¥ìˆ˜ ê´€ë ¨ ë³µì¡í•œ ì§ˆë¬¸ì— ëŒ€í•œ ê¸°ë³¸ ì‘ë‹µ"""
    user_query = None
    for m in reversed(state["messages"]):
        if isinstance(m, HumanMessage):
            user_query = m.content
            break
    if not user_query:
        user_query = "(empty)"
    
    fallback_response = (
        f"â“ '{user_query}' ë” ëª…í™•í•œ ì„¤ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤.\n"
        f"ğŸ‘‰ ì§ˆë¬¸ì„ êµ¬ì²´ì ìœ¼ë¡œ ë‹¤ì‹œ ì‘ì„±í•´ ì£¼ì„¸ìš”.\n"
        f"ğŸ’¡ ë˜ëŠ” í–¥ìˆ˜ì— ê´€í•œ ë©‹ì§„ ì§ˆë¬¸ì„ í•´ë³´ì‹œëŠ” ê±´ ì–´ë–¨ê¹Œìš”?"
    )
    
    msgs = state["messages"] + [AIMessage(content=fallback_response)]
    return {"messages": msgs, "next": None, "router_json": state.get("router_json")}

# ---------- 5) ì§ì ‘ ë„êµ¬ í˜¸ì¶œ ë°©ì‹ìœ¼ë¡œ ì—ì´ì „íŠ¸ êµ¬í˜„ ----------
def price_agent_node(state: AgentState) -> AgentState:
    """Price agent - ì§ì ‘ ë„êµ¬ í˜¸ì¶œ"""
    user_query = None
    for m in reversed(state["messages"]):
        if isinstance(m, HumanMessage):
            user_query = m.content
            break
    if not user_query:
        user_query = "(empty)"
    
    try:
        # ì§ì ‘ price_tool í˜¸ì¶œ
        price_result = price_tool.invoke({"user_query": user_query})
        
        # ê²°ê³¼ë¥¼ ë” ìì—°ìŠ¤ëŸ½ê²Œ í¬ë§·íŒ…
        final_answer = f"ğŸ’° **ê°€ê²© ì •ë³´**\n\n{price_result}"
        
        msgs = state["messages"] + [AIMessage(content=final_answer)]
        return {
            "messages": msgs, 
            "next": None, 
            "router_json": state.get("router_json")
        }
    except Exception as e:
        error_msg = f"âŒ ê°€ê²© ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        msgs = state["messages"] + [AIMessage(content=error_msg)]
        return {
            "messages": msgs, 
            "next": None, 
            "router_json": state.get("router_json")
        }

def FAQ_agent_node(state: AgentState) -> AgentState:
    """FAQ agent - LLM ê¸°ë³¸ ì§€ì‹ìœ¼ë¡œ í–¥ìˆ˜ ê´€ë ¨ ì§ˆë¬¸ ë‹µë³€"""
    user_query = None
    for m in reversed(state["messages"]):
        if isinstance(m, HumanMessage):
            user_query = m.content
            break
    if not user_query:
        user_query = "(empty)"
    
    try:
        # LLMì—ê²Œ í–¥ìˆ˜ ì§€ì‹ ì „ë¬¸ê°€ë¡œì„œ ë‹µë³€í•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ ì„¤ì •
        faq_prompt = ChatPromptTemplate.from_messages([
            ("system", """You are a perfume expert. Provide accurate and helpful information for usersâ€™ perfume-related questions.

You can cover topics such as:
- Perfume types and concentrations (EDT, EDP, Parfum, etc.)
- Fragrance notes and ingredients (top/middle/base) and their roles
- Brand characteristics and signature fragrances
- How to apply and store perfumes properly
- Tips for choosing perfumes by season and occasion
- Longevity (lasting power) and projection/sillage

Keep your tone friendly, explanations easy to understand, and include practical, actionable advice.
Please answer in Korean."""),
            ("user", "{question}")
        ])
        
        chain = faq_prompt | llm
        result = chain.invoke({"question": user_query})
        
        # ê²°ê³¼ë¥¼ í¬ë§·íŒ…
        final_answer = f"ğŸ“š **í–¥ìˆ˜ ì§€ì‹**\n\n{result.content}"
        
        msgs = state["messages"] + [AIMessage(content=final_answer)]
        return {
            "messages": msgs, 
            "next": None, 
            "router_json": state.get("router_json")
        }
    except Exception as e:
        error_msg = f"âŒ í–¥ìˆ˜ ì§€ì‹ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        msgs = state["messages"] + [AIMessage(content=error_msg)]
        return {
            "messages": msgs, 
            "next": None, 
            "router_json": state.get("router_json")
        }

def ML_agent_node(state: AgentState) -> AgentState:
    """ML agent - recommend_perfume_simple ë„êµ¬ í˜¸ì¶œ í›„, LLMì´ ì„¤ëª…ë¬¸ ìƒì„±ê¹Œì§€ ìˆ˜í–‰"""
    user_query = None
    for m in reversed(state["messages"]):
        if isinstance(m, HumanMessage):
            user_query = m.content
            break
    if not user_query:
        user_query = "(empty)"

    try:
        # 1) ML ë„êµ¬ í˜¸ì¶œ (êµ¬ì¡°í™” ë°ì´í„° ë³´ì¡´)
        ml_result = recommend_perfume_simple.invoke({"user_text": user_query})
        # ì˜ˆìƒ êµ¬ì¡°: {"recommendations": [...], "predicted_labels": [...]}
        ml_json_str = json.dumps(ml_result, ensure_ascii=False)

        # 2) LLMì— ì»¨í…ìŠ¤íŠ¸ë¡œ ì „ë‹¬í•˜ì—¬ ìì—°ì–´ ë‹µë³€ ìƒì„±
        system_prompt = """
You are a perfume recommendation explainer. The JSON below is the ML model's recommendation output; base your response solely on that information and craft a concise, friendly answer.

- Summarize the top 3 picks aligned with the user's intent, each with a key reason.
- If predicted scent attributes are present, show them in one line.
- Suggest about two similar alternatives and a next step (e.g., ask about season/time-of-day/longevity preferences).
- Do not exaggerate or invent any facts not present in the JSON.

Please answer in Korean.
"""
        human_prompt = (
            f"ì‚¬ìš©ì ì§ˆë¬¸:\n{user_query}\n\n"
            f"ML ì¶”ì²œ JSON:\n```json\n{ml_json_str}\n```"
        )

        llm_out = llm.invoke([SystemMessage(content=system_prompt),
                              HumanMessage(content=human_prompt)])

        # 3) ìµœì¢… ë‹µë³€ì„ ëŒ€í™”ì— ì¶”ê°€
        msgs = state["messages"] + [AIMessage(content=llm_out.content)]
        return {
            "messages": msgs,
            "next": None,
            "router_json": state.get("router_json")
        }

    except Exception as e:
        error_msg = f"âŒ ML ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        msgs = state["messages"] + [AIMessage(content=error_msg)]
        return {
            "messages": msgs,
            "next": None,
            "router_json": state.get("router_json")
        }
# ---------- 7) Build Graph ----------
graph = StateGraph(AgentState)

# ë…¸ë“œ ì¶”ê°€
graph.add_node("supervisor", supervisor_node)
graph.add_node("LLM_parser", LLM_parser_node)
graph.add_node("FAQ_agent", FAQ_agent_node)
graph.add_node("human_fallback", human_fallback_node)
graph.add_node("price_agent", price_agent_node)
graph.add_node("ML_agent", ML_agent_node)

# ì‹œì‘ì  ì„¤ì •
graph.set_entry_point("supervisor")

# ì¡°ê±´ë¶€ ë¼ìš°íŒ… í•¨ìˆ˜
def router_edge(state: AgentState) -> str:
    return state["next"] or "human_fallback"

# ì¡°ê±´ë¶€ ì—£ì§€ ì¶”ê°€ (supervisorì—ì„œ ê° agentë¡œ)
graph.add_conditional_edges(
    "supervisor",
    router_edge,
    {
        "LLM_parser": "LLM_parser",
        "FAQ_agent": "FAQ_agent",
        "human_fallback": "human_fallback",
        "price_agent": "price_agent",
        "ML_agent": "ML_agent",
    },
)

# ê° ì—ì´ì „íŠ¸ì—ì„œ ENDë¡œ ê°€ëŠ” ì—£ì§€ ì¶”ê°€
for node in ["LLM_parser", "FAQ_agent", "human_fallback", "price_agent", "ML_agent"]:
    graph.add_edge(node, END)

# ê·¸ë˜í”„ ì»´íŒŒì¼
app = graph.compile()


TEST_QUERIES = [
    # ë¸Œëœë“œ/ë†ë„/ì‚¬ì´ì¦ˆ/ê³„ì ˆ/ë‚®ë°¤ â†’ ë³µí•© ì¡°ê±´ ì§ˆë¬¸
    "ì…ìƒë¡œë‘ ì—¬ì„±ìš© 50ml ê²¨ìš¸ìš© í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜. ê°€ê²©ë„ ì•Œë ¤ì¤˜",
    "ë””ì˜¬ EDPë¡œ ê°€ì„ ë°¤(ì•¼ê°„)ì— ì“¸ ë§Œí•œ í–¥ìˆ˜ ìˆì–´?",
    "ìƒ¤ë„¬ ë‚¨ì„±ìš© ì—¬ë¦„ìš© ì˜¤ ë“œ ëšœì™ˆë › ì¶”ì²œí•´ì¤˜",
    "ì¡°ë§ë¡  í”Œë¡œëŸ´ ê³„ì—´ ê°€ì„ ë‚®ìš© ì¶”ì²œí•´ì¤˜",
    "í†°í¬ë“œ ìš°ë”” ê³„ì—´ ê²¨ìš¸ ë°¤ìš© 100ml í–¥ìˆ˜ ìˆì–´?",
    "í¬ë¦¬ë“œ ì‹œíŠ¸ëŸ¬ìŠ¤ í–¥, ì—¬ë¦„ ë‚®ìš© 50ml ì¶”ì²œí•´ì¤˜",
    "êµ¬ì°Œ ì—¬ì„±ìš© ì˜¤ ë“œ í¼í“¸ ê°€ì„ìš© ì¶”ì²œí•´ì¤„ë˜?",
    "í”„ë¼ë‹¤ ë‚¨ì„±ìš© ìŠ¤íŒŒì´ì‹œ í–¥, ë´„ ë°¤ìš© 30ml ë­ ìˆì–´?",
    "ì—ë¥´ë©”ìŠ¤ 100ml í”Œë¡œëŸ´ í–¥, ì—¬ë¦„ ë‚®ìš© ì¶”ì²œí•´ì¤˜",
    "ì…ìƒë¡œë‘ ì—¬ì„±ìš© ì˜¤ ë“œ í¼í“¸, ê²¨ìš¸ ë°¤ìš© í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜",

    # ë‹¨ì¼ ê°œë… ì§ˆë¬¸
    "EDPë‘ EDT ì°¨ì´ê°€ ë­ì•¼?",
    "íƒ‘ë…¸íŠ¸Â·ë¯¸ë“¤ë…¸íŠ¸Â·ë² ì´ìŠ¤ë…¸íŠ¸ê°€ ê°ê° ë¬´ìŠ¨ ëœ»ì´ì•¼?",
    "ë‹ˆì¹˜ í–¥ìˆ˜ë‘ ë””ìì´ë„ˆ í–¥ìˆ˜ ì°¨ì´ê°€ ê¶ê¸ˆí•´",
    "ì—¬ì„±ìš©ì´ë‘ ë‚¨ì„±ìš© í–¥ìˆ˜ëŠ” ì‹¤ì œë¡œ ì„±ë¶„ì´ ë‹¬ë¼?",
    "ì”í–¥ì´ ê°•í•œ í–¥ìˆ˜ë‘ ì•½í•œ í–¥ìˆ˜ì˜ ì°¨ì´ëŠ” ë­ì•¼?",
    "í”„ë£¨í‹° í–¥ìˆ˜ë‘ êµ¬ë¥´ë§ í–¥ìˆ˜ ì°¨ì´ ì•Œë ¤ì¤˜",
    "ë¨¸ìŠ¤í¬ë‘ ì•°ë²„ í–¥ì€ ì–´ë–»ê²Œ ë‹¬ë¼?",
    "ì‹œíŠ¸ëŸ¬ìŠ¤ ê³„ì—´ê³¼ í”Œë¡œëŸ´ ê³„ì—´ì€ ì–´ë–¤ ì°¨ì´ê°€ ìˆì–´?",
    "ìƒ¤ë„¬ ë„˜ë²„5ë‘ ì½”ì½”ë§ˆë“œëª¨ì•„ì ¤ì€ ì–´ë–¤ ì°¨ì´ê°€ ìˆì–´?",
    "ì˜¤ ë“œ í¼í“¸ê³¼ íŒŒë¥´í­ ì°¨ì´ê°€ ë­ì•¼?",

    # í–¥ìˆ˜ì™€ ë¬´ê´€í•œ ì§ˆë¬¸
    "ì˜¤ëŠ˜ ì ì‹¬ ë­ ë¨¹ì„ê¹Œ?",
    "ì˜¤ëŠ˜ ì„œìš¸ ë‚ ì”¨ ì–´ë•Œ?",
    "ì£¼ë§ì— ì–´ë”” ê°ˆê¹Œ?",
    "ë„·í”Œë¦­ìŠ¤ì—ì„œ ë­ ë³¼ë§Œí•´?",
    "ìš”ì¦˜ ì£¼ì‹ ì–´ë•Œ?",
    "ì¶•êµ¬ ê²½ê¸° ëª‡ ì‹œì— ì‹œì‘í•´?",
    "ì„œìš¸ì—ì„œ ì¹´í˜ ì¶”ì²œí•´ì¤˜",
    "ì»¤í”¼ë‘ ì°¨ ì¤‘ì— ë­ê°€ ë” ê±´ê°•í•´?",
    "ìŠ¤ë§ˆíŠ¸í° ìƒˆ ëª¨ë¸ ë‚˜ì™”ì–´?",
    "ë¹„ ì˜¬ê¹Œ ë‚´ì¼?",

    # í–¥ë§Œ ë¬»ëŠ” ì§ˆë¬¸
    "ì—¬ë¦„ì— ì‹œì›í•œ í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜.",
    "ë‹¬ë‹¬í•œ í–¥ ì¶”ì²œí•´ì¤˜.",
    "ìƒí¼í•œ í–¥ì€ ë­ì•¼?",
    "ë”°ëœ»í•œ í–¥ ì¶”ì²œí•´ì¤˜.",
    "ìš°ë””í•œ í–¥ì´ ë­ì•¼?",
    "ìŠ¤íŒŒì´ì‹œí•œ í–¥ìˆ˜ ì•Œë ¤ì¤˜.",
    "ë°”ë‹ë¼ ê°™ì€ ë‹¬ì½¤í•œ í–¥ ìˆì§€?",
    "ë°”ë‹¤ ê°™ì€ í–¥ì€ ë­ë¼ í•´?",
    "ì¥ë¯¸ í–¥ ë§ê³  í”Œë¡œëŸ´ í–¥ì€ ë­ ìˆì–´?",
    "ì»¤í”¼ ê°™ì€ í–¥ì´ ë‚˜ëŠ” í–¥ìˆ˜ë„ ìˆì–´?",

    # ê°€ê²©ë§Œ ë¬»ëŠ” ì§ˆë¬¸
    "ìƒ¤ë„¬ ë„˜ë²„5 50ml ê°€ê²© ì•Œë ¤ì¤˜.",
    "ë””ì˜¬ ì†Œë°”ì¥¬ ê°€ê²© ì–¼ë§ˆì•¼? ì–´ë””ì„œ ì‚¬ëŠ” ê²Œ ì œì¼ ì‹¸?",
    "ë”¥í‹°í¬ ë„ ì† ê°€ê²© ì–¼ë§ˆì•¼?",
    "ë¶ˆê°€ë¦¬ ì˜´ë‹ˆì•„ í¬ë¦¬ìŠ¤íƒˆë¦° ê°€ê²© ì•Œë ¤ì¤˜.",
    "ì¡°ë§ë¡  ì‰ê¸€ë¦¬ì‰¬ í˜ì–´ ì•¤ í”„ë¦¬ì§€ì•„ ìµœì €ê°€ ì°¾ì•„ì¤˜.",
    "í†°í¬ë“œ ì˜¤ë“œìš°ë“œ 30ml ê°€ê²©ëŒ€ ì•Œë ¤ì¤˜.",
    "í¬ë¦¬ë“œ ì–´ë²¤íˆ¬ìŠ¤ ë‚¨ì„±ìš© ê°€ê²© ì•Œë ¤ì¤˜.",
    "í”„ë¼ë‹¤ ìº”ë”” EDP ê°€ê²© ì•Œë ¤ì¤˜.",
    "êµ¬ì°Œ ë¸”ë£¸ 100ml ê°€ê²©ëŒ€ ì•Œì•„ë´.",
    "ì—ë¥´ë©”ìŠ¤ ë–¼ë¥´ë°ë¥´ë©”ìŠ¤ ì–¼ë§ˆ ì •ë„ í•´?",

    # ê¸°íƒ€ (ë…¸ì´ì¦ˆì„±/ì‹¤í—˜ìš©)
    "ë°”ë³´ê°™ì€í–¥ ì¶”ì²œí•´ì¤˜"
]
OUTPUT_FILE = "results.txt"

def run_tests():
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        for q in TEST_QUERIES:
            f.write("="*80 + "\n")
            f.write("Query: " + q + "\n")
            init: AgentState = {
                "messages": [HumanMessage(content=q)],
                "next": None,
                "router_json": None
            }
            try:
                out = app.invoke(init)
                ai_msgs = [m for m in out["messages"] if isinstance(m, AIMessage)]
                router_raw = ai_msgs[-2].content if len(ai_msgs) >= 2 else "(no router output)"
                agent_summary = ai_msgs[-1].content if ai_msgs else "(no agent output)"
                f.write("Router JSON: " + router_raw + "\n")
                f.write("Agent summary: " + agent_summary + "\n\n")
            except Exception as e:
                f.write(f"Error processing query: {e}\n\n")

def run_single_query(query: str):
    with open(OUTPUT_FILE, "a", encoding="utf-8") as f:
        f.write(f"ğŸ” Query: {query}\n")
        f.write("-" * 50 + "\n")
        
        init: AgentState = {
            "messages": [HumanMessage(content=query)],
            "next": None,
            "router_json": None
        }
        
        try:
            out = app.invoke(init)
            ai_msgs = [m for m in out["messages"] if isinstance(m, AIMessage)]
            
            if len(ai_msgs) >= 2:
                f.write("ğŸ¤– Router Decision:\n")
                f.write(ai_msgs[-2].content + "\n")
                f.write("\nğŸ“ Final Response:\n")
                f.write(ai_msgs[-1].content + "\n\n")
            elif len(ai_msgs) == 1:
                f.write("ğŸ“ Response:\n")
                f.write(ai_msgs[-1].content + "\n\n")
            else:
                f.write("âŒ No response generated\n\n")
                
        except Exception as e:
            f.write(f"âŒ Error: {e}\n\n")

if __name__ == "__main__":
    print("ğŸ”§ í™˜ê²½ ë³€ìˆ˜ í™•ì¸:")
    print(f"OPENAI_API_KEY: {'âœ… ì„¤ì •ë¨' if os.getenv('OPENAI_API_KEY') else 'âŒ ë¯¸ì„¤ì •'}")
    print(f"PINECONE_API_KEY: {'âœ… ì„¤ì •ë¨' if os.getenv('PINECONE_API_KEY') else 'âŒ ë¯¸ì„¤ì •'}")
    print(f"NAVER_CLIENT_ID: {'âœ… ì„¤ì •ë¨' if os.getenv('NAVER_CLIENT_ID') else 'âŒ ë¯¸ì„¤ì •'}")
    print(f"NAVER_CLIENT_SECRET: {'âœ… ì„¤ì •ë¨' if os.getenv('NAVER_CLIENT_SECRET') else 'âŒ ë¯¸ì„¤ì •'}")
    print()
    
    print("ğŸš€ í–¥ìˆ˜ ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘... ê²°ê³¼ëŠ” results.txt íŒŒì¼ì— ì €ì¥ë©ë‹ˆë‹¤.")
    print()
    
    run_tests()